{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 3\n",
    "\n",
    "**Question 1.** Write a python program using Textblob in which find out the parts-of-speech(pos) tagging from the following sentence.\n",
    "\n",
    "\"Susie works in a shoeshine shop. Where she shines she sits, and where she sits she shines\"\n",
    "\n",
    "**Question 2.** What is Wordlist? And, how it is different than tokenization?\n",
    "\n",
    "**Question 3.** Write a python program using the textblob to find out the count of the common words from the following sentence.\n",
    "\n",
    "\"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
    "He would chuck, he would, as much as he could, and chuck as much wood\n",
    "As a woodchuck would if a woodchuck could chuck wood\"\n",
    "Find it out how many times 'wood' came in the sentence.\n",
    "\n",
    "**Question 4.** Translate the following sentences in your own language using the textblob.\n",
    "\n",
    "\"Data is a new oil.\", \"A.I is the last invention\", \"She sells seashells by the seashore\", \"He threw three free throws\".\n",
    "\n",
    "**Question 5.** Create a spell checker program using the textblob library with using your own sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\00004829\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\00004829\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.50.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\00004829\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\00004829\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\00004829\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.10.15)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\00004829\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1. Write a python program using Textblob in which find out the parts-of-speech(pos) tagging from the following sentence.\n",
    "\n",
    "\"Susie works in a shoeshine shop. Where she shines she sits, and where she sits she shines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Susie', 'NNP'),\n",
       " ('works', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('shoeshine', 'NN'),\n",
       " ('shop', 'NN'),\n",
       " ('Where', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('shines', 'VBZ'),\n",
       " ('she', 'PRP'),\n",
       " ('sits', 'VBZ'),\n",
       " ('and', 'CC'),\n",
       " ('where', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('sits', 'VBZ'),\n",
       " ('she', 'PRP'),\n",
       " ('shines', 'NNS')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "text=\"Susie works in a shoeshine shop. Where she shines she sits, and where she sits she shines\"\n",
    "pos_text=TextBlob(text)\n",
    "pos_text.tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. What is Wordlist? And, how it is different than tokenization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization:\n",
      " ['Susie', 'work', 'in', 'a', 'shoeshine', 'shop', 'Where', 'she', 'shine', 'she', 'sits', 'and', 'where', 'she', 'sits', 'she', 'shine']\n",
      "Stemming:\n",
      " ['susi', 'work', 'in', 'a', 'shoeshin', 'shop', 'where', 'she', 'shine', 'she', 'sit', 'and', 'where', 'she', 'sit', 'she', 'shine']\n",
      "Singularizing:\n",
      " work\n",
      "Singularizing:\n",
      " Wheres\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Defination:A wordlist is a python list of words that got extracted from the sentence that is passed as the argument.\n",
    "When compared to tokenization, wordlist has additional methods like singulaize,pluralize along with list methods.\n",
    "We can do stemming and lemmatization as well on the words using wordlist.Below is the sample code:\n",
    "\"\"\"\n",
    "from textblob import TextBlob\n",
    "text=\"Susie works in a shoeshine shop. Where she shines she sits, and where she sits she shines\"\n",
    "text_blob=TextBlob(text)\n",
    "print(\"Lemmatization:\\n\",text_blob.words.lemmatize())\n",
    "print(\"Stemming:\\n\",text_blob.words.stem())\n",
    "print(\"Singularizing:\\n\",text_blob.words[1].singularize())\n",
    "print(\"Singularizing:\\n\",text_blob.words[6].pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3. Write a python program using the textblob to find out the count of the common words from the following sentence.\n",
    "\n",
    "\"How much wood would a woodchuck chuck if a woodchuck could chuck wood? He would chuck, he would, as much as he could, and chuck as much wood As a woodchuck would if a woodchuck could chuck wood\" \n",
    "\n",
    "Find it out how many times 'wood' came in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of times wood appeared as a seperate word in the sentence is: 4\n",
      "No. of times wood appeared as a string in the sentence is: 8\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "text=\"How much wood would a woodchuck chuck if a woodchuck could chuck wood? He would chuck, he would, as much as he could, and chuck as much wood As a woodchuck would if a woodchuck could chuck wood\"\n",
    "txt_blob=TextBlob(text)\n",
    "print(\"No. of times wood appeared as a seperate word in the sentence is:\",txt_blob.words.count('wood'))\n",
    "print(\"No. of times wood appeared as a string in the sentence is:\",len(re.findall('wood',text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4. Translate the following sentences in your own language using the textblob.\n",
    "\n",
    "\"Data is a new oil.\", \"A.I is the last invention\", \"She sells seashells by the seashore\", \"He threw three free throws\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enlish Sentence             Telugu Sentence\n",
      "--------------------------------------------\n",
      "Data is a new oil.    ->    డేటా కొత్త నూనె.\n",
      "A.I is the last invention    ->    A.I చివరి ఆవిష్కరణ\n",
      "She sells seashells by the seashore    ->    ఆమె సముద్ర తీరం ద్వారా సముద్రపు గవ్వలను విక్రయిస్తుంది\n",
      "He threw three free throws    ->    అతను మూడు ఉచిత త్రోలు విసిరాడు\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "text_list=[\"Data is a new oil.\", \"A.I is the last invention\", \"She sells seashells by the seashore\", \"He threw three free throws\"]\n",
    "telugu_list=[]\n",
    "print(\"Enlish Sentence             Telugu Sentence\")\n",
    "print(\"--------------------------------------------\")\n",
    "for txt in text_list:\n",
    "    text_blob=TextBlob(txt)    \n",
    "    print(txt,\"   ->   \", text_blob.translate(to='te'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5. Create a spell checker program using the textblob library with using your own sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before spelling correction is:  sentece is havig corrct speling!\n",
      "Sentence after spelling correction is:  sentence is having correct spelling!\n",
      "List before correction: \n",
      " ['A.I is the lastt inventon', ' the seashre', 'He thrw threee free throws']\n",
      "List after correction: \n",
      " [TextBlob(\"A.I is the last invention\"), TextBlob(\" the seashore\"), TextBlob(\"He threw three free throws\")]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "text=\"sentece is havig corrct speling!\"\n",
    "text_list=[ \"A.I is the lastt inventon\", \" the seashre\", \"He thrw threee free throws\"]\n",
    "def spell_chkr(txt):\n",
    "    text_blob=TextBlob(txt)\n",
    "    return text_blob.correct()\n",
    "print(\"Sentence before spelling correction is: \",text)\n",
    "print(\"Sentence after spelling correction is: \",spell_chkr(text))\n",
    "print(\"List before correction: \\n\",text_list)\n",
    "crct_list=[]\n",
    "for i in text_list:\n",
    "    crct_list.append(spell_chkr(i))\n",
    "print(\"List after correction: \\n\",crct_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
