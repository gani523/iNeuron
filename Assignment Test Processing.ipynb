{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2\n",
    "\n",
    "**Question 1.** Write a python program to find out the words after '@' from the below sentences with the use of regex.\n",
    "\n",
    "\"xyz@gmail.com\",\n",
    "\"abc@yahoo.com\",\n",
    "\"xyz@hotmail.com\",\n",
    "\"abc@ineuron.ai\",\n",
    "\"xyz@outlook.com\"\n",
    "\n",
    "**Question 2.** Write a python program with the use of regex to take out the word \"New\" from the following sentence.\n",
    "\n",
    "[\"New Delhi is the capital of India\"]\n",
    "\n",
    "**Question 3.** Create one python program in which you have to lowercase the sentence first and than delete digits from the following sentence.\n",
    "\n",
    "\"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
    "\n",
    "**Question 4.** Do stemming, lemmatization and tokenization from the following sentence.\n",
    "\n",
    "\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\"\n",
    "\n",
    "**Question 5.** Create one python program from the following sentence.\n",
    "\n",
    "\"I love NLP, not you\"\n",
    "\n",
    "output : ['I', 'l', 'N', 'n', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   #### Question 1. Write a python program to find out the words after '@' from the below sentences with the use of regex.\n",
    "\n",
    "    \"xyz@gmail.com\", \n",
    "    \"abc@yahoo.com\", \n",
    "    \"xyz@hotmail.com\",\n",
    "    \"abc@ineuron.ai\", \n",
    "    \"xyz@outlook.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmail\n",
      "yahoo\n",
      "hotmail\n",
      "ineuron\n",
      "outlook\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text=[\"xyz@gmail.com\", \"abc@yahoo.com\", \"xyz@hotmail.com\",\"abc@ineuron.ai\",\"xyz@outlook.com\"]\n",
    "words=[]\n",
    "for i,x in enumerate(text):\n",
    "    words.extend(re.findall(r'@(\\w+)', x))\n",
    "for i in words:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. Write a python program with the use of regex to take out the word \"New\" from the following sentence.\n",
    "\n",
    "[\"New Delhi is the capital of India\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text=\"New Delhi is the capital of India\"\n",
    "re.findall(\"New\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3. Create one python program in which you have to lowercase the sentence first and than delete digits from the following sentence.\n",
    "\n",
    "\"In India, 184 people got affected with Corona virus and 4 are died.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution 1: in india,  people got affected with corona virus and  are died.\n",
      "Solution 2: in india,  people got affected with corona virus and  are died.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_n(x):\n",
    "    res=re.sub('\\d+','',x)\n",
    "    return res\n",
    "\n",
    "text=\"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
    "\n",
    "print('Solution 1:',remove_n(text.lower()))\n",
    "\n",
    "#Solution 2:\n",
    "text=\"In India, 184 people got affected with Corona virus and 4 are died.\"\n",
    "print('Solution 2:',re.sub('\\d+','',text.lower()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4. Do stemming, lemmatization and tokenization from the following sentence.\n",
    "\n",
    "\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words after stemming:\n",
      " ['hawai', '.', 'built', 'when', 'that', 'have', ',', 'abl', 'hope', 'to', 'save', 'be', 'I', 'travel', 'will', 'my', 'up']\n",
      "Words after lemmatization:\n",
      " ['Hawai', '.', 'built', 'when', 'that', 'have', ',', 'able', 'hope', 'to', 'saving', 'be', 'I', 'travel', 'will', 'my', 'up']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\00004829\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\00004829\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import wordnet\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "sen=\"I hope that, when I have built up my savings, I will be able to travel to Hawai.\"\n",
    "stem1=PorterStemmer()\n",
    "lemma=wordnet.WordNetLemmatizer()\n",
    "\n",
    "def stemming_fun(sentence):\n",
    "    words=word_tokenize(sentence)\n",
    "    stem_words=[stem1.stem(word) for word in set(words)]\n",
    "    return stem_words\n",
    "def lemma_fun(sentence):\n",
    "    words=word_tokenize(sentence)\n",
    "    lemma_words=[lemma.lemmatize(word) for word in set(words)]\n",
    "    return lemma_words\n",
    "\n",
    "print(\"Words after stemming:\\n\",stemming_fun(sen))\n",
    "print(\"Words after lemmatization:\\n\",lemma_fun(sen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5. Create one python program from the following sentence.\n",
    "\n",
    "\"I love NLP, not you\"\n",
    "\n",
    "output : ['I', 'l', 'N', 'n', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'l', 'N', 'n', 'y']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text=\"I love NLP, not you\"\n",
    "split_words=text.split()\n",
    "output=[]\n",
    "for i in split_words:\n",
    "    output.extend(re.findall('^.',i))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
